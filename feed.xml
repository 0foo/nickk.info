<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" /><updated>2023-11-16T23:59:02+00:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">Your awesome title</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Working around API request limits with bulk IP proxy</title><link href="http://0.0.0.0:4000/2023/11/16/api-limits.html" rel="alternate" type="text/html" title="Working around API request limits with bulk IP proxy" /><published>2023-11-16T12:06:00+00:00</published><updated>2023-11-16T12:06:00+00:00</updated><id>http://0.0.0.0:4000/2023/11/16/api-limits</id><content type="html" xml:base="http://0.0.0.0:4000/2023/11/16/api-limits.html"><![CDATA[<p>Most websites have API request limits <strong>based on IP</strong> which make scraping or bulk data collection on their sites prohibitive.</p>

<p>Scraping and data collection requires a LOT of requests for each new page of data which would be rather quickly rate limited, slowing down your data collection to unsatisfactory speeds.</p>

<p>So what’s the solution?  Send each request through a unique IP!</p>

<p>There exists companies which specialize in Bulk IP proxying, and have bulk amounts of IP’s, which, for a small fee, will let you proxy all of your requests through their network which, if all goes well, should give you unique IP per request goodness.</p>

<p>I found one of these IP providers called IPRoyal.</p>

<p>IPRoyal claims to have a network of 8 million residential IP’s!!!</p>

<p>If this is true and if this works this is extremely awesome.</p>

<p>I signed up for IPRoyal and forked over the 7 bucks to see what happens.</p>

<!--more-->

<hr class="article-separator-more" />

<p>To begin, let’s run a non-proxied reddit.com query with a curl statment to see how quickly we get rate limited.</p>

<p>As everyone knows, 200 status code is a successful request and 429 status code is a blocked reqest due to rate limit.</p>

<p>Let’s see if we can get blocked by reddit.</p>

<p>(Note: These are async responses, so the responses are unordered. Had to async these for speed. )</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nick@nick-XPS-9315:~<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..1000<span class="o">}</span><span class="p">;</span> <span class="k">do</span> /bin/bash <span class="nt">-c</span> <span class="s1">'curl  -sL -o /dev/null -w "%{http_code} " https://www.reddit.com &amp;'</span><span class="p">;</span> <span class="k">done</span><span class="p">;</span>
nick@nick-XPS-9315:~<span class="nv">$ </span>429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 200 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 429 200 429 429 429 429 429 429 429 429 429 429 429 429 429 429 200 429 429 200 429 200 200 429 200 200 200 429 200 429 429 200 429 200 200 200 429 429 200 429 200 200 200 429....
</code></pre></div></div>

<p>Rate limited almost immediately LOL!</p>

<hr class="article-separator-more" />

<p>So let’s try with the IPRoyal network.</p>

<p>So, for 7 bucks IPRoyal gives you 1gig worth of data.</p>

<p>To use their network you are provided with a hash/url combo which you can configure as a proxy via proxy application or combine for curl.</p>

<p>Now let’s try with the IPRoyal proxy. :) (-x being the curl proxy flag)</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">IPRoyalProxy</span><span class="o">=</span><span class="s2">"http://&lt;someBigHash&gt;@geo.iproyal.com:12321"</span>
nick@nick-XPS-9315:~<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..1000<span class="o">}</span><span class="p">;</span> <span class="k">do</span> /bin/bash <span class="nt">-c</span> <span class="s2">"curl  -s -o /dev/null -w </span><span class="se">\"</span><span class="s2">%{http_code} </span><span class="se">\"</span><span class="s2"> -I -x </span><span class="nv">$IPRoyalProxy</span><span class="s2"> -L https://www.reddit.com &amp;"</span><span class="p">;</span> <span class="k">done</span><span class="p">;</span>
nick@nick-XPS-9315:~<span class="nv">$ </span>200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 000 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 .....
</code></pre></div></div>

<p><br />
Not a single 429!!<br />
Now that’s cooking with GAS!!! <br />
IPRoyal is pretty pretty cool.<br />
In the next post we’re going to combine this with some sort of scraper or web spider to try and scrape all of the comment’s of a Reddit user.</p>]]></content><author><name></name></author><category term="networking" /><summary type="html"><![CDATA[Most websites have API request limits based on IP which make scraping or bulk data collection on their sites prohibitive. Scraping and data collection requires a LOT of requests for each new page of data which would be rather quickly rate limited, slowing down your data collection to unsatisfactory speeds. So what’s the solution? Send each request through a unique IP! There exists companies which specialize in Bulk IP proxying, and have bulk amounts of IP’s, which, for a small fee, will let you proxy all of your requests through their network which, if all goes well, should give you unique IP per request goodness. I found one of these IP providers called IPRoyal. IPRoyal claims to have a network of 8 million residential IP’s!!! If this is true and if this works this is extremely awesome. I signed up for IPRoyal and forked over the 7 bucks to see what happens.]]></summary></entry><entry><title type="html">Weather Data Mining</title><link href="http://0.0.0.0:4000/2023/09/06/weather-data-mining.html" rel="alternate" type="text/html" title="Weather Data Mining" /><published>2023-09-06T12:16:00+00:00</published><updated>2023-09-06T12:16:00+00:00</updated><id>http://0.0.0.0:4000/2023/09/06/weather-data-mining</id><content type="html" xml:base="http://0.0.0.0:4000/2023/09/06/weather-data-mining.html"><![CDATA[<p>In order to find places to live or visit where I can maximize the amount of time I’m able to comfortably spend outside I wrote a script to calculate the locations in the US with temperatures between 30 degrees and 75 degrees for 6 months or more.
<br /><br /></p>

<ul>
  <li>All the data comes from NOAA weather stations and can be downloaded here: <a href="https://www.ncei.noaa.gov/pub/data/ghcn/daily/">link</a></li>
  <li>The github repo is here: <a href="https://github.com/0foo/weather_mining">https://github.com/0foo/weather_mining</a></li>
  <li>The interactive google map is here: <a href="https://www.google.com/maps/d/edit?mid=11qYJOQ2cX9j3T-x5UO5ykXmjUToSdEs&amp;ll=42.70028862623725%2C-119.24163318010127&amp;z=7">link</a>
<br /><br /></li>
</ul>

<p><!--more--></p>

<p><u>Interesting observations:</u></p>

<ul>
  <li>
    <p>Looks like the crown for perfect temps year round goes to the Pacific Northwest including northern California, Oregon, and Washington.  Many locations there have perfect temps 12 months out of the year.</p>
  </li>
  <li>
    <p>The entire West coast fared really well with most of it experiencing comfortable temps most of the year with a few months slightly deviating into cold or hot.</p>
  </li>
  <li>
    <p>There’s a swath of the southeastern part of the country that has more than 6 months of comfortable temps that curves up the east coast, however almost all of the east/southeast locations cap out at 7 or 8 months of comfortable temps, which doesn’t reach west coast comfort levels of 8+ months typically.</p>
  </li>
</ul>

<p><br /></p>

<p><u>To Do (when have time) </u></p>
<ul>
  <li>At some point would like to convert this to a dynamic site where you can plot migration patterns to stay in comfortable weather for traveling retired or digital nomads.</li>
  <li>Would like to be able to dynamically input your own custom comfortable temp ranges as peoples idea of comfortable temps and temp tolerances may vary.</li>
  <li>At some point would like to include other weather factors like sunshine, preciptation, snowfall</li>
</ul>

<p><br /><br /></p>

<ul>
  <li>Note: on this map the field labeled count is months within the comfort zone of 30 to 75.
<br /></li>
</ul>
<iframe src="https://www.google.com/maps/d/embed?mid=11qYJOQ2cX9j3T-x5UO5ykXmjUToSdEs&amp;ehbc=2E312F" width="100%" height="800"></iframe>]]></content><author><name></name></author><summary type="html"><![CDATA[In order to find places to live or visit where I can maximize the amount of time I’m able to comfortably spend outside I wrote a script to calculate the locations in the US with temperatures between 30 degrees and 75 degrees for 6 months or more. All the data comes from NOAA weather stations and can be downloaded here: link The github repo is here: https://github.com/0foo/weather_mining The interactive google map is here: link]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://0.0.0.0:4000/noaa.jpeg" /><media:content medium="image" url="http://0.0.0.0:4000/noaa.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Terrible Implementations of Is Even</title><link href="http://0.0.0.0:4000/2023/09/02/is-even.html" rel="alternate" type="text/html" title="Terrible Implementations of Is Even" /><published>2023-09-02T12:06:00+00:00</published><updated>2023-09-02T12:06:00+00:00</updated><id>http://0.0.0.0:4000/2023/09/02/is-even</id><content type="html" xml:base="http://0.0.0.0:4000/2023/09/02/is-even.html"><![CDATA[<p>I stumbled on this written as a joke somewhere on the web and found it hilariously terrible. <br />
What a way to turn a O(1) modulus operation into the glorious abomination you see here.  <br />
This algorithm has a runtime of O(2^n). <br /></p>

<!--more-->

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">is_even</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="nf">abs</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>
  <span class="c1"># x is even if it can be divided into two parts y and z that equal each other
</span>  <span class="n">y</span><span class="p">,</span><span class="n">z</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mi">0</span>
  <span class="c1"># take turns incrementing y and z
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nf">is_even</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
      <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="nf">return </span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">z</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Runtime(x) = Runtime(x-1) + Runtime(x-2) + ... + Runtime(0)  
Runtime(x-1) = Runtime(x-2) + Runtime(x-3) + ... + Runtime(0)  
Runtime(x) = 2 * Runtime(x-1) = 2 * 2 * Runtime(x-2) = ... = 2 * 2 * 2 * ... * Runtime(0) = 2^x * const. 

</code></pre></div></div>]]></content><author><name></name></author><category term="algorithms" /><summary type="html"><![CDATA[I stumbled on this written as a joke somewhere on the web and found it hilariously terrible. What a way to turn a O(1) modulus operation into the glorious abomination you see here. This algorithm has a runtime of O(2^n).]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://0.0.0.0:4000/20231102_081138.jpg" /><media:content medium="image" url="http://0.0.0.0:4000/20231102_081138.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>